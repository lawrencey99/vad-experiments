{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VADDNN(nn.Module):\n",
    "    def __init__(self, input_size=40, output_size=496, dropout=0.5):\n",
    "        super(VADDNN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_size, 256)\n",
    "        self.linear_2 = nn.Linear(256, 256)\n",
    "        self.linear_3 = nn.Linear(256, 256)\n",
    "        self.linear_4 = nn.Linear(256, 256)\n",
    "        self.linear_5 = nn.Linear(256, output_size)\n",
    "        self.dropout_1 = nn.Dropout(p=dropout)\n",
    "        self.dropout_2 = nn.Dropout(p=dropout)\n",
    "            \n",
    "    def forward(self, x, out_keys):\n",
    "        out = {}\n",
    "        out['h1'] = nn.functional.relu(self.linear_1(x))\n",
    "        out['h2'] = nn.functional.relu(self.linear_2(out['h1']))\n",
    "        out['h3'] = nn.functional.relu(self.linear_3(self.dropout_1(out['h2'])))\n",
    "        out['h4'] = nn.functional.relu(self.linear_3(self.dropout_2(out['h3'])))\n",
    "        out['out'] = nn.functional.relu(self.linear_5(out['h4']))\n",
    "        return [out[key] for key in out_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-74-55a14ba5d295>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-55a14ba5d295>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    np.save('Yvals.np', newY)\u001b[0m\n\u001b[0m                             \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"audio_folder = '/home/ubuntu/vad-experiments/dataset/LibriSpeech/train-clean-100/'\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "speakers = os.listdir(audio_folder)\n",
    "speaker2id = {}\n",
    "flac_files = []\n",
    "for speaker_id, speaker in enumerate(speakers):\n",
    "    speaker2id[speaker] = speaker_id\n",
    "    \n",
    "for root, dirs, files in os.walk(\"/home/ubuntu/vad-experiments/dataset/LibriSpeech/train-clean-100\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".flac\"):\n",
    "             flac_files.append(os.path.join(root, file))\n",
    "print(len(flac_files))\n",
    "for file_num, audio_file in enumerate(flac_files):\n",
    "    speaker = os.path.basename(os.path.dirname(os.path.dirname(audio_file)))\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    num_samples = y.shape[0]\n",
    "    int_seconds = int(num_samples/sr)\n",
    "    y = y[:int_seconds * sr]\n",
    "    samples = np.array(np.split(y, int_seconds))\n",
    "    mfccs = []\n",
    "    for i in range(len(samples)):\n",
    "        X.append(np.mean(librosa.feature.mfcc(y=samples[i], sr=sr, n_mfcc=40).T,axis=0))\n",
    "    Y += [speaker2id[speaker]] * len(samples)\n",
    "    print(file_num)\n",
    "newX = np.array(X)\n",
    "newY = np.array(Y).reshape(-1, 1)\n",
    "np.save('Xvals.np', newX)\n",
    "np.save('Yvals.np', newY)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347745, 40) float32\n",
      "(347745, 1) int64\n"
     ]
    }
   ],
   "source": [
    "X = np.load('Xvals.np.npy')\n",
    "Y = np.load('Yvals.np.npy')\n",
    "print(X.shape, X.dtype)\n",
    "print(Y.shape, Y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
